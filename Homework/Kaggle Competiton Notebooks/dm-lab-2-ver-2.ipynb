{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7133801,"sourceType":"datasetVersion","datasetId":4116120},{"sourceId":7280327,"sourceType":"datasetVersion","datasetId":4221199}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-27T13:57:19.024829Z","iopub.execute_input":"2023-12-27T13:57:19.025570Z","iopub.status.idle":"2023-12-27T13:57:19.541284Z","shell.execute_reply.started":"2023-12-27T13:57:19.025515Z","shell.execute_reply":"2023-12-27T13:57:19.540006Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/emotionsdata/sampleSubmission.csv\n/kaggle/input/emotionsdata/data_identification.csv\n/kaggle/input/emotionsdata/emotion.csv\n/kaggle/input/cleanedtweet/cleaned_tweets.pkl\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nimport matplotlib.pyplot as plt\nimport gc  \nimport string\nimport re\nfrom wordcloud import WordCloud\n# import contractions\nimport nltk\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nimport spacy\nimport re\nimport emoji\nimport regex # count features\nfrom textblob import TextBlob","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:19.543485Z","iopub.execute_input":"2023-12-27T13:57:19.544046Z","iopub.status.idle":"2023-12-27T13:57:28.552375Z","shell.execute_reply.started":"2023-12-27T13:57:19.544010Z","shell.execute_reply":"2023-12-27T13:57:28.551402Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# !pip install smart_open==5.1.0\n!pip install --upgrade gensim smart_open\n","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:28.556379Z","iopub.execute_input":"2023-12-27T13:57:28.557113Z","iopub.status.idle":"2023-12-27T13:57:45.652579Z","shell.execute_reply.started":"2023-12-27T13:57:28.557074Z","shell.execute_reply":"2023-12-27T13:57:45.651172Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gensim in /opt/conda/lib/python3.10/site-packages (4.3.2)\nRequirement already satisfied: smart_open in /opt/conda/lib/python3.10/site-packages (6.3.0)\nCollecting smart_open\n  Obtaining dependency information for smart_open from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.24.3)\nRequirement already satisfied: scipy>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from gensim) (1.11.4)\nDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: smart_open\n  Attempting uninstall: smart_open\n    Found existing installation: smart-open 6.3.0\n    Uninstalling smart-open-6.3.0:\n      Successfully uninstalled smart-open-6.3.0\nSuccessfully installed smart_open-6.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\n# Load data_identification DataFrame\ndata_identification = pd.read_csv('/kaggle/input/emotionsdata/data_identification.csv')\nimport pandas as pd\n\n# Load emotion_data DataFrame\nemotion_data = pd.read_csv('/kaggle/input/emotionsdata/emotion.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:45.655662Z","iopub.execute_input":"2023-12-27T13:57:45.656169Z","iopub.status.idle":"2023-12-27T13:57:48.946638Z","shell.execute_reply.started":"2023-12-27T13:57:45.656135Z","shell.execute_reply":"2023-12-27T13:57:48.945221Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Load the Pickle file into a DataFrame\ncleaned_tweet_df = pd.read_pickle('/kaggle/input/cleanedtweet/cleaned_tweets.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:48.948198Z","iopub.execute_input":"2023-12-27T13:57:48.948573Z","iopub.status.idle":"2023-12-27T13:57:53.359325Z","shell.execute_reply.started":"2023-12-27T13:57:48.948541Z","shell.execute_reply":"2023-12-27T13:57:53.358053Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ncleaned_tweet_df = pd.read_pickle('/kaggle/input/cleanedtweet/cleaned_tweets.pkl')\n\n# Ensure that cleaned_tweet_df is a DataFrame\ncleaned_tweet_df = pd.DataFrame(cleaned_tweet_df)\n\n# Print the first few rows\nprint(cleaned_tweet_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:53.361107Z","iopub.execute_input":"2023-12-27T13:57:53.361552Z","iopub.status.idle":"2023-12-27T13:57:55.546709Z","shell.execute_reply.started":"2023-12-27T13:57:53.361511Z","shell.execute_reply":"2023-12-27T13:57:55.545527Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"   tweet_id                                               text  \\\n0  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n2  0x28b412  Confident of your obedience, I write to you, k...   \n3  0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>   \n4  0x2de201  \"Trust is not the same as faith. A friend is s...   \n\n                            cleaned_text_with_emojis  \n0    people post add I snapchat dehydrate cuz man lh  \n1  trump dangerous freepress world lh lh trumpleg...  \n2  confident obedience I write know I ask philemo...  \n3                                issa stalk tasha lh  \n4  trust faith friend trust faith mistake christo...  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Merge cleaned_tweet_df with emotion_data on 'tweet_id'\ncleaned_and_emotion_df = pd.merge(cleaned_tweet_df, emotion_data, on='tweet_id', how='left')\n\n# Display the first few rows of the merged DataFrame\nprint(cleaned_and_emotion_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:55.548053Z","iopub.execute_input":"2023-12-27T13:57:55.548393Z","iopub.status.idle":"2023-12-27T13:57:58.973629Z","shell.execute_reply.started":"2023-12-27T13:57:55.548365Z","shell.execute_reply":"2023-12-27T13:57:58.972503Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"   tweet_id                                               text  \\\n0  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n2  0x28b412  Confident of your obedience, I write to you, k...   \n3  0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>   \n4  0x2de201  \"Trust is not the same as faith. A friend is s...   \n\n                            cleaned_text_with_emojis       emotion  \n0    people post add I snapchat dehydrate cuz man lh  anticipation  \n1  trump dangerous freepress world lh lh trumpleg...       sadness  \n2  confident obedience I write know I ask philemo...           NaN  \n3                                issa stalk tasha lh          fear  \n4  trust faith friend trust faith mistake christo...           NaN  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Merge the merged_cleaned_and_emotion with data_identification\nmerged_df = pd.merge(cleaned_and_emotion_df, data_identification, on='tweet_id', how='left')\n\n# Display the first few rows of the final merged dataframe\nprint(merged_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:57:58.975085Z","iopub.execute_input":"2023-12-27T13:57:58.975556Z","iopub.status.idle":"2023-12-27T13:58:02.877925Z","shell.execute_reply.started":"2023-12-27T13:57:58.975528Z","shell.execute_reply":"2023-12-27T13:58:02.876513Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"   tweet_id                                               text  \\\n0  0x376b20  People who post \"add me on #Snapchat\" must be ...   \n1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...   \n2  0x28b412  Confident of your obedience, I write to you, k...   \n3  0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>   \n4  0x2de201  \"Trust is not the same as faith. A friend is s...   \n\n                            cleaned_text_with_emojis       emotion  \\\n0    people post add I snapchat dehydrate cuz man lh  anticipation   \n1  trump dangerous freepress world lh lh trumpleg...       sadness   \n2  confident obedience I write know I ask philemo...           NaN   \n3                                issa stalk tasha lh          fear   \n4  trust faith friend trust faith mistake christo...           NaN   \n\n  identification  \n0          train  \n1          train  \n2           test  \n3          train  \n4           test  \n","output_type":"stream"}]},{"cell_type":"code","source":"# Separate the data into training and testing sets\ntrain_df = merged_df[merged_df['identification'] == 'train']\ntest_df = merged_df[merged_df['identification'] == 'test']\n\n# Display the shapes of the training and testing sets\nprint(\"Training Data Shape:\", train_df.shape)\nprint(\"Testing Data Shape:\", test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:58:02.879833Z","iopub.execute_input":"2023-12-27T13:58:02.880291Z","iopub.status.idle":"2023-12-27T13:58:03.799665Z","shell.execute_reply.started":"2023-12-27T13:58:02.880251Z","shell.execute_reply":"2023-12-27T13:58:03.798410Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training Data Shape: (1455563, 5)\nTesting Data Shape: (411972, 5)\n","output_type":"stream"}]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-27T13:58:03.802886Z","iopub.execute_input":"2023-12-27T13:58:03.803301Z","iopub.status.idle":"2023-12-27T13:58:03.825297Z","shell.execute_reply.started":"2023-12-27T13:58:03.803265Z","shell.execute_reply":"2023-12-27T13:58:03.824090Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"    tweet_id                                               text  \\\n2   0x28b412  Confident of your obedience, I write to you, k...   \n4   0x2de201  \"Trust is not the same as faith. A friend is s...   \n9   0x218443  When do you have enough ? When are you satisfi...   \n30  0x2939d5  God woke you up, now chase the day #GodsPlan #...   \n33  0x26289a  In these tough times, who do YOU turn to as yo...   \n\n                             cleaned_text_with_emojis emotion identification  \n2   confident obedience I write know I ask philemo...     NaN           test  \n4   trust faith friend trust faith mistake christo...     NaN           test  \n9   satisfied goal money materialism money possess...     NaN           test  \n30            god wake chase day godsplan godswork lh     NaN           test  \n33                     tough time turn symbol hope lh     NaN           test  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>text</th>\n      <th>cleaned_text_with_emojis</th>\n      <th>emotion</th>\n      <th>identification</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0x28b412</td>\n      <td>Confident of your obedience, I write to you, k...</td>\n      <td>confident obedience I write know I ask philemo...</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0x2de201</td>\n      <td>\"Trust is not the same as faith. A friend is s...</td>\n      <td>trust faith friend trust faith mistake christo...</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0x218443</td>\n      <td>When do you have enough ? When are you satisfi...</td>\n      <td>satisfied goal money materialism money possess...</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0x2939d5</td>\n      <td>God woke you up, now chase the day #GodsPlan #...</td>\n      <td>god wake chase day godsplan godswork lh</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0x26289a</td>\n      <td>In these tough times, who do YOU turn to as yo...</td>\n      <td>tough time turn symbol hope lh</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Drop rows with missing values in the 'emotion' column\ntrain_df_cleaned = train_df.dropna(subset=['emotion'])\n\n# Feature Extraction\ntfidf_vectorizer = TfidfVectorizer(max_features=50000, stop_words='english', ngram_range=(1, 3), max_df=0.85, min_df=2, sublinear_tf=True)\nX_train = tfidf_vectorizer.fit_transform(train_df_cleaned['cleaned_text_with_emojis'])\ny_train = train_df_cleaned['emotion']\n\n# Hyperparameter Tuning with Class Weights\nparam_grid = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0, 500.0, 1000.0]}  # Adjusted alpha values\ngrid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='f1_weighted')\ngrid_search.fit(X_train, y_train)\nbest_alpha = grid_search.best_params_['alpha']\n\n# Building and Training the Naive Bayes Model with the best alpha and default class weights\nX_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\nnb_classifier = MultinomialNB(alpha=best_alpha)\nnb_classifier.fit(X_train_split, y_train_split)\n\n# Predict on the validation set\ny_val_pred = nb_classifier.predict(X_val_split)\n\n# Evaluate the performance on the validation set\nprint(\"Validation Accuracy:\", accuracy_score(y_val_split, y_val_pred))\nprint(\"\\nClassification Report:\\n\", classification_report(y_val_split, y_val_pred))\n\n# Feature extraction for test data\nX_test = tfidf_vectorizer.transform(test_df['cleaned_text_with_emojis'])\n\n# Predicting emotions in test data\ntest_df['predicted_emotion'] = nb_classifier.predict(X_test)\n\n# Creating a submission file\nsubmission_df = test_df[['tweet_id', 'predicted_emotion']].rename(columns={'tweet_id': 'id'})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-27T15:42:07.212629Z","iopub.execute_input":"2023-12-27T15:42:07.213996Z","iopub.status.idle":"2023-12-27T16:02:17.586963Z","shell.execute_reply.started":"2023-12-27T15:42:07.213946Z","shell.execute_reply":"2023-12-27T16:02:17.585356Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.5210863135620876\n\nClassification Report:\n               precision    recall  f1-score   support\n\n       anger       0.61      0.16      0.26      7973\nanticipation       0.60      0.51      0.55     49787\n     disgust       0.41      0.41      0.41     27820\n        fear       0.60      0.34      0.43     12800\n         joy       0.53      0.77      0.63    103204\n     sadness       0.44      0.43      0.44     38687\n    surprise       0.62      0.15      0.25      9746\n       trust       0.53      0.27      0.36     41096\n\n    accuracy                           0.52    291113\n   macro avg       0.54      0.38      0.42    291113\nweighted avg       0.53      0.52      0.50    291113\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_42/1319764661.py:37: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_df['predicted_emotion'] = nb_classifier.predict(X_test)\n","output_type":"stream"}]}]}